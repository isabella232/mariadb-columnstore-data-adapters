<?xml version="1.0" encoding="UTF-8"?>
<job>
  <name>test</name>
  <description/>
  <extended_description/>
  <job_version/>
  <job_status>0</job_status>
  <directory>/</directory>
  <created_user>-</created_user>
  <created_date>2018/01/29 10:51:53.584</created_date>
  <modified_user>-</modified_user>
  <modified_date>2018/01/29 10:51:53.584</modified_date>
  <parameters>
    <parameter>
      <name>COLUMNSTORE_XML</name>
      <default_value>/usr/local/mariadb/columnstore/etc/Columnstore.xml</default_value>
      <description>Path to Columnstore.xml</description>
    </parameter>
    <parameter>
      <name>DB_HOST</name>
      <default_value>127.0.0.1</default_value>
      <description>MariaDB hostname or IP</description>
    </parameter>
    <parameter>
      <name>DB_NAME</name>
      <default_value>test</default_value>
      <description>Database name</description>
    </parameter>
    <parameter>
      <name>DB_PASS</name>
      <default_value />
      <description>Database password</description>
    </parameter>
    <parameter>
      <name>DB_PORT</name>
      <default_value>3306</default_value>
      <description>MariaDB port</description>
    </parameter>
    <parameter>
      <name>DB_USER</name>
      <default_value>root</default_value>
      <description>Database user</description>
    </parameter>
    <parameter>
      <name>TEST_CLEAN_SCRIPT</name>
      <default_value>${Internal.Entry.Current.Directory}/test_clean.sh</default_value>
      <description>Script to clean the csv files after testing</description>
    </parameter>
    <parameter>
      <name>TEST_EVALUATION_SCRIPT</name>
      <default_value>${Internal.Entry.Current.Directory}/test_eval.sh</default_value>
      <description>Script to evaluate if test succeeds or fails</description>
    </parameter>
  </parameters>
  <connection>
    <name>MariaDB JDBC</name>
    <server>${DB_HOST}</server>
    <type>MARIADB</type>
    <access>Native</access>
    <database>${DB_NAME}</database>
    <port>${DB_PORT}</port>
    <username>${DB_USER}</username>
    <password>${DB_PASS}</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <slaveservers>
    </slaveservers>
  <job-log-table>
    <connection/>
    <schema/>
    <table/>
    <size_limit_lines/>
    <interval/>
    <timeout_days/>
    <field>
      <id>ID_JOB</id>
      <enabled>Y</enabled>
      <name>ID_JOB</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>JOBNAME</name>
    </field>
    <field>
      <id>STATUS</id>
      <enabled>Y</enabled>
      <name>STATUS</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>STARTDATE</id>
      <enabled>Y</enabled>
      <name>STARTDATE</name>
    </field>
    <field>
      <id>ENDDATE</id>
      <enabled>Y</enabled>
      <name>ENDDATE</name>
    </field>
    <field>
      <id>LOGDATE</id>
      <enabled>Y</enabled>
      <name>LOGDATE</name>
    </field>
    <field>
      <id>DEPDATE</id>
      <enabled>Y</enabled>
      <name>DEPDATE</name>
    </field>
    <field>
      <id>REPLAYDATE</id>
      <enabled>Y</enabled>
      <name>REPLAYDATE</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>Y</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>EXECUTING_SERVER</id>
      <enabled>N</enabled>
      <name>EXECUTING_SERVER</name>
    </field>
    <field>
      <id>EXECUTING_USER</id>
      <enabled>N</enabled>
      <name>EXECUTING_USER</name>
    </field>
    <field>
      <id>START_JOB_ENTRY</id>
      <enabled>N</enabled>
      <name>START_JOB_ENTRY</name>
    </field>
    <field>
      <id>CLIENT</id>
      <enabled>N</enabled>
      <name>CLIENT</name>
    </field>
  </job-log-table>
  <jobentry-log-table>
    <connection/>
    <schema/>
    <table/>
    <timeout_days/>
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>TRANSNAME</name>
    </field>
    <field>
      <id>JOBENTRYNAME</id>
      <enabled>Y</enabled>
      <name>STEPNAME</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>RESULT</id>
      <enabled>Y</enabled>
      <name>RESULT</name>
    </field>
    <field>
      <id>NR_RESULT_ROWS</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_ROWS</name>
    </field>
    <field>
      <id>NR_RESULT_FILES</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_FILES</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>N</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>COPY_NR</id>
      <enabled>N</enabled>
      <name>COPY_NR</name>
    </field>
  </jobentry-log-table>
  <channel-log-table>
    <connection/>
    <schema/>
    <table/>
    <timeout_days/>
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>LOGGING_OBJECT_TYPE</id>
      <enabled>Y</enabled>
      <name>LOGGING_OBJECT_TYPE</name>
    </field>
    <field>
      <id>OBJECT_NAME</id>
      <enabled>Y</enabled>
      <name>OBJECT_NAME</name>
    </field>
    <field>
      <id>OBJECT_COPY</id>
      <enabled>Y</enabled>
      <name>OBJECT_COPY</name>
    </field>
    <field>
      <id>REPOSITORY_DIRECTORY</id>
      <enabled>Y</enabled>
      <name>REPOSITORY_DIRECTORY</name>
    </field>
    <field>
      <id>FILENAME</id>
      <enabled>Y</enabled>
      <name>FILENAME</name>
    </field>
    <field>
      <id>OBJECT_ID</id>
      <enabled>Y</enabled>
      <name>OBJECT_ID</name>
    </field>
    <field>
      <id>OBJECT_REVISION</id>
      <enabled>Y</enabled>
      <name>OBJECT_REVISION</name>
    </field>
    <field>
      <id>PARENT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>PARENT_CHANNEL_ID</name>
    </field>
    <field>
      <id>ROOT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>ROOT_CHANNEL_ID</name>
    </field>
  </channel-log-table>
  <pass_batchid>N</pass_batchid>
  <shared_objects_file/>
  <entries>
    <entry>
      <name>export to database</name>
      <description/>
      <type>TRANS</type>
      <specification_method>filename</specification_method>
      <trans_object_id/>
      <filename>${Internal.Entry.Current.Directory}/export-to-mariadb.ktr</filename>
      <transname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name/>
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration>Pentaho local</run_configuration>
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>368</xloc>
      <yloc>160</yloc>
    </entry>
    <entry>
      <name>START</name>
      <description/>
      <type>SPECIAL</type>
      <start>Y</start>
      <dummy>N</dummy>
      <repeat>N</repeat>
      <schedulerType>0</schedulerType>
      <intervalSeconds>0</intervalSeconds>
      <intervalMinutes>60</intervalMinutes>
      <hour>12</hour>
      <minutes>0</minutes>
      <weekDay>1</weekDay>
      <DayOfMonth>1</DayOfMonth>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>80</xloc>
      <yloc>160</yloc>
    </entry>
    <entry>
      <name>write into csv</name>
      <description/>
      <type>TRANS</type>
      <specification_method>filename</specification_method>
      <trans_object_id/>
      <filename>${Internal.Entry.Current.Directory}/export-to-csv.ktr</filename>
      <transname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile/>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name/>
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration>Pentaho local</run_configuration>
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>528</xloc>
      <yloc>160</yloc>
    </entry>
    <entry>
      <name>prepare tables</name>
      <description/>
      <type>SQL</type>
      <sql>DROP TABLE IF EXISTS kettle_test_data; 
CREATE TABLE IF NOT EXISTS kettle_test_data
(
  uint64 BIGINT UNSIGNED
, int64 BIGINT
, uint32 INT UNSIGNED
, int32 INT
, uint16 SMALLINT UNSIGNED
, int16 SMALLINT
, uint8 TINYINT UNSIGNED
, intEight TINYINT
, f FLOAT
, d DOUBLE
, ch4 VARCHAR(5)
, vch30 VARCHAR(30)
, dt DATE
, dtm DATETIME(6)
, dc DECIMAL(18)
, tx TEXT
, bit TINYINT(1)
, mathInt BIGINT UNSIGNED
, dc2 DECIMAL(18,9)
)
;
INSERT INTO kettle_test_data VALUES (1, 2, 3, 4, 5, 6, 7, 8, 1.234, 2.34567, "ABCD", "Hello World", "2017-09-08", "2017-09-08 13:58:23", 123, "Hello World Longer", true, 9223372036854775807, -0.000000001);
INSERT INTO kettle_test_data VALUES (0, -9223372036854775806, 0, -2147483646, 0, -32766, 0, -126, 1.234, 2.34567, "A", "B", "1000-01-01", "1000-01-01 00:00:00", -123, "C", false, 18446744073709551613, 100000000.999999999);
INSERT INTO test.kettle_test_data VALUES (9223372036854775807, 9223372036854775807, 4294967293, 2147483647, 65533, 32767, 253, 127, 1.234, 2.34567, "ZYXW", "012345678901234567890123456789", "9999-12-31", "9999-12-31 23:59:59.999999", 123, "012345678901234567890123456789", true, 2342, 23.42);

DROP TABLE IF EXISTS kettle_jdbc_innodb;
CREATE TABLE IF NOT EXISTS kettle_jdbc_innodb
(
  uint64 BIGINT UNSIGNED
, int64 BIGINT
, uint32 INT UNSIGNED
, int32 INT
, uint16 SMALLINT UNSIGNED
, int16 SMALLINT
, uint8 TINYINT UNSIGNED
, intEight TINYINT
, f FLOAT
, d DOUBLE
, ch4 VARCHAR(5)
, vch30 VARCHAR(30)
, dt DATE
, dtm DATETIME(6)
, dc DECIMAL(18)
, tx TEXT
, bit TINYINT(1)
, mathInt BIGINT UNSIGNED
, dc2 DECIMAL(18,9)
)
;

DROP TABLE IF EXISTS kettle_jdbc_columnstore;
CREATE TABLE IF NOT EXISTS kettle_jdbc_columnstore
(
  uint64 BIGINT UNSIGNED
, int64 BIGINT
, uint32 INT UNSIGNED
, int32 INT
, uint16 SMALLINT UNSIGNED
, int16 SMALLINT
, uint8 TINYINT UNSIGNED
, intEight TINYINT
, f FLOAT
, d DOUBLE
, ch4 VARCHAR(5)
, vch30 VARCHAR(30)
, dt DATE
, dtm DATETIME(6)
, dc DECIMAL(18)
, tx TEXT
, bit TINYINT(1)
, mathInt BIGINT UNSIGNED
, dc2 DECIMAL(18,9)
)
engine=columnstore
;

DROP TABLE IF EXISTS kettle_api_columnstore;
CREATE TABLE IF NOT EXISTS kettle_api_columnstore
(
  uint64 BIGINT UNSIGNED
, vch30 VARCHAR(30)
, int64 BIGINT
, uint32 INT UNSIGNED
, tx TEXT
, int32 INT
, uint16 SMALLINT UNSIGNED
, int16 SMALLINT
, uint8 TINYINT UNSIGNED
, intEight TINYINT
, f FLOAT
, d DOUBLE
, ch4 VARCHAR(5)
, bit TINYINT(1)
, dt DATE
, dtm DATETIME(6)
, dc DECIMAL(18)
, mathInt BIGINT UNSIGNED
, dc2 DECIMAL(18,9)
)
engine=columnstore
;</sql>
      <useVariableSubstitution>F</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename>${Internal.Entry.Current.Directory}/prepare-tables.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>MariaDB JDBC</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>208</xloc>
      <yloc>160</yloc>
    </entry>
    <entry>
      <name>validate test</name>
      <description/>
      <type>SHELL</type>
      <filename>${TEST_EVALUATION_SCRIPT}</filename>
      <work_directory>${Internal.Entry.Current.Directory}</work_directory>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>N</insertScript>
      <script />
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>672</xloc>
      <yloc>160</yloc>
    </entry>
    <entry>
      <name>Success</name>
      <description/>
      <type>SUCCESS</type>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>1120</xloc>
      <yloc>160</yloc>
    </entry>
    <entry>
      <name>clean csv files</name>
      <description/>
      <type>SHELL</type>
      <filename>${TEST_CLEAN_SCRIPT}</filename>
      <work_directory>${Internal.Entry.Current.Directory}</work_directory>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>N</insertScript>
      <script />
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>976</xloc>
      <yloc>160</yloc>
    </entry>
    <entry>
      <name>clean database</name>
      <description/>
      <type>SQL</type>
      <sql>DROP TABLE kettle_api_columnstore;
DROP TABLE kettle_jdbc_columnstore;
DROP TABLE kettle_jdbc_innodb;
DROP TABLE kettle_test_data;</sql>
      <useVariableSubstitution>F</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>MariaDB JDBC</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>832</xloc>
      <yloc>160</yloc>
    </entry>
  </entries>
  <hops>
    <hop>
      <from>export to database</from>
      <to>write into csv</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>START</from>
      <to>prepare tables</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>prepare tables</from>
      <to>export to database</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>write into csv</from>
      <to>validate test</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>clean csv files</from>
      <to>Success</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>validate test</from>
      <to>clean database</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>clean database</from>
      <to>clean csv files</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
  </hops>
  <notepads>
  </notepads>
  <attributes>
    <group>
      <name>METASTORE.pentaho</name>
      <attribute>
        <key>Default Run Configuration</key>
        <value>{"namespace":"pentaho","id":"Default Run Configuration","name":"Default Run Configuration","description":"Defines a default run configuration","metaStoreName":null}</value>
      </attribute>
    </group>
    <group>
      <name>{"_":"Embedded MetaStore Elements","namespace":"pentaho","type":"Default Run Configuration"}</name>
      <attribute>
        <key>Pentaho local</key>
        <value>{"children":[{"children":[],"id":"server","value":null},{"children":[],"id":"clustered","value":"N"},{"children":[],"id":"name","value":"Pentaho local"},{"children":[],"id":"description","value":null},{"children":[],"id":"pentaho","value":"N"},{"children":[],"id":"readOnly","value":"Y"},{"children":[],"id":"sendResources","value":"N"},{"children":[],"id":"logRemoteExecutionLocally","value":"N"},{"children":[],"id":"remote","value":"N"},{"children":[],"id":"local","value":"Y"},{"children":[],"id":"showTransformations","value":"N"}],"id":"Pentaho local","value":null,"name":"Pentaho local","owner":null,"ownerPermissionsList":[]}</value>
      </attribute>
    </group>
  </attributes>
</job>
